{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from handler.clients.am_api.client import get_accounts\n",
    "from handler.clients.am_api.requests import GetAccountRequest\n",
    "from handler.clients.content_api.client import (\n",
    "    get_answers,\n",
    "    get_question_count,\n",
    "    get_questions,\n",
    "    get_section_count,\n",
    "    get_sections,\n",
    "    get_knowledge_bases\n",
    ")\n",
    "from handler.clients.content_api.requests import GetAnswerRequest, GetQuestionRequest, GetSectionRequest, GetKnowledgeBaseRequest\n",
    "from handler.handler import Handler\n",
    "\n",
    "h = Handler(token=os.environ['INTERNAL_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all \n",
    "r_account = GetAccountRequest()\n",
    "accounts = get_accounts(h, r_account)\n",
    "industries = [response.industry for response in accounts]\n",
    "accounts_ids = [response.id for response in accounts]\n",
    "print(industries)\n",
    "print(accounts_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the histogram of industries with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(industries, alpha=0.5, color='g')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Industries for Accounts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_account_ids = []\n",
    "kb_langs = []\n",
    "kb_industries = []\n",
    "kb_ids = []\n",
    "kb_section_counts = []\n",
    "kb_generated_question_counts = []\n",
    "kb_gpt_question_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (account_id, industry) in enumerate(zip(accounts_ids, industries)):\n",
    "    r_kb = GetKnowledgeBaseRequest(account_id=account_id)\n",
    "    print(f\"Account {account_id} - {industry} - {i+1}/{len(accounts_ids)}\")\n",
    "    for kb in get_knowledge_bases(h, r_kb):\n",
    "        # Disable if want to collect for all languages\n",
    "        if(kb.language in ['en', 'da']):\n",
    "            kb_account_ids.append(account_id)\n",
    "            kb_industries.append(industry)\n",
    "\n",
    "            kb_langs.append(kb.language)\n",
    "            kb_ids.append(kb.id)\n",
    "\n",
    "\n",
    "            r_sections = GetSectionRequest(knowledge_base_id=kb.id)\n",
    "            section_count = get_section_count(h, r_sections)\n",
    "            kb_section_counts.append(section_count)\n",
    "\n",
    "            r_generated_questions = GetQuestionRequest(knowledge_base_id=kb.id, data_source='api.gpt-35-turbo')\n",
    "            generated_question_count = get_question_count(h, r_generated_questions)\n",
    "            kb_generated_question_counts.append(generated_question_count)\n",
    "\n",
    "            r_gpt_questions = GetQuestionRequest(knowledge_base_id=kb.id, data_source='api.gpt-35-turbo')\n",
    "            gpt_question_count = get_question_count(h, r_gpt_questions)\n",
    "            kb_gpt_question_counts.append(gpt_question_count)\n",
    "\n",
    "        print(f\"   KB {kb.id} - {kb.language} - {section_count} sections - {generated_question_count} generated questions - {gpt_question_count} gpt questions\")  # noqa: E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = zip(kb_account_ids,  kb_langs, kb_industries, kb_ids, kb_section_counts, kb_generated_question_counts, kb_gpt_question_counts)\n",
    "# save to csv\n",
    "with open('knowledge_bases_full.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['account_id', 'language', 'industry', 'knowledge_base_id', 'section_count', 'generated_question_count', 'gpt_question_count'])\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nicely formatted table, with kb_account_ids, kb_ids, kb_langs, kb_industries, kb_section_counts, kb_question_counts, where\n",
    "# there is color coding for the section and question counts (independent of each other) based on the number of sections and questions\n",
    "# use some default color scheme for this\n",
    "import pandas as pd\n",
    "df = pd.read_csv('knowledge_bases_full.csv')\n",
    "df.to_html('knowledge_bases.html', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate toy data\n",
    "\n",
    "\n",
    "\n",
    "# Convert your data to a pandas DataFrame\n",
    "# Instead o loading from lists, load directly from the csv\n",
    "\n",
    "# Drop rows with NaN values in industry field\n",
    "df = df.dropna()\n",
    "\n",
    "# Group by Industries and Langs, and calculate the sum of Section_Counts and Question_Counts\n",
    "grouped = df[df['language'].isin(['da'])].groupby(['industry', 'language']).sum()[['section_count', 'generated_question_count']].reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Get unique industries and languages\n",
    "unique_industries = grouped['industry'].unique()\n",
    "unique_langs = grouped['language'].unique()\n",
    "\n",
    "# Define the width of the bars and the positions of the bars on the x-axis\n",
    "bar_width = 0.15\n",
    "r1 = np.arange(len(unique_industries))\n",
    "\n",
    "# Create a new figure with a specified size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# For each language, create bars for section counts and question counts\n",
    "for i, lang in enumerate(unique_langs):\n",
    "    data_by_lang = grouped.loc[grouped['language'] == lang]\n",
    "    for j, count_type in enumerate(['generated_question_count']):\n",
    "        r = np.array([x + bar_width*(i+j) for x in r1])\n",
    "        counts = data_by_lang[count_type]\n",
    "        r = r[np.isin(unique_industries, data_by_lang['industry'])]\n",
    "        plt.bar(r, counts, width=bar_width, edgecolor='grey', label=f'{count_type} ({lang})')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('industry', fontweight='bold')\n",
    "plt.xticks([r + bar_width*1.5 for r in range(len(unique_industries))], unique_industries, rotation=45)\n",
    "# plt.ylim(0, 5_000)\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accounts by industries and plot accounts by number of kb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_questions is a list of dictionaries.\n",
    "# Save to .jsonl file\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "\n",
    "df = df.dropna()\n",
    "danish_df = df[df['language'].isin(['da'])]\n",
    "total_industry_sizes = {unique_industries[i]: counts[i] for i in range(len(unique_industries))}\n",
    "\n",
    "questions_per_industry = 5000\n",
    "\n",
    "for index, row in danish_df[['industry', 'generated_question_count', 'knowledge_base_id']].iterrows():\n",
    "    (industry, generated_question_count, kb_id) = row\n",
    "    print(row)\n",
    "    r_questions = GetQuestionRequest(knowledge_base_id=kb_id, label_method_type='generated')\n",
    "    questions = get_questions(h, r_questions)\n",
    "    industry_size = total_industry_sizes[industry]\n",
    "    proportion = generated_question_count / industry_size\n",
    "    proportional_question_count = math.floor(proportion * questions_per_industry)\n",
    "    chosen_questions = random.sample(questions, proportional_question_count)\n",
    "    # print(proportional_question_count)\n",
    "    corresponding_sections_ids = [question.section_id for question in chosen_questions if question.section_id is not None]\n",
    "    # print(corresponding_sections_ids)\n",
    "    r_sections = GetSectionRequest(knowledge_base_id=kb_id, ids=corresponding_sections_ids)\n",
    "    corresponding_sections= get_sections(h, r_sections)\n",
    "\n",
    "    with open('generated_questions_2.jsonl', 'a') as f:\n",
    "        for question in chosen_questions:\n",
    "            f.write(question.model_dump_json() + '\\n')\n",
    "    with open('corresponding_sections_2.jsonl', 'a') as f:\n",
    "        for section in corresponding_sections:\n",
    "            f.write(section.model_dump_json() + '\\n')\n",
    "    print(f\"{index} / {len(danish_df)} Industry {industry} - {generated_question_count} questions - {proportional_question_count}\")\n",
    "    \n",
    "# print(os.path.getsize('generated_questions.jsonl') / (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ('Finance', 5796, 293)\n",
    "(industry, generated_question_count, kb_id) = row\n",
    "r_questions = GetQuestionRequest(knowledge_base_id=kb_id, label_method_type='generated')\n",
    "questions = get_questions(h, r_questions)\n",
    "industry_size = total_industry_sizes[industry]\n",
    "proportion = generated_question_count / industry_size\n",
    "proportional_question_count = math.floor(proportion * generated_question_count)\n",
    "chosen_questions = random.sample(questions, proportional_question_count)\n",
    "\n",
    "corresponding_sections_ids = [question.section_id for question in chosen_questions]\n",
    "r_sections = GetSectionRequest(knowledge_base_id=kb_id, ids=corresponding_sections_ids)\n",
    "corresponding_sections= get_sections(h, r_sections)\n",
    "\n",
    "with open('generated_questions_2.jsonl', 'a') as f:\n",
    "    for question in chosen_questions:\n",
    "        f.write(json.dumps(question.model_dump_json()) + '\\n')\n",
    "with open('corresponding_sections_2.jsonl', 'a') as f:\n",
    "    for section in corresponding_sections:\n",
    "        f.write(json.dumps(section.model_dump_json()) + '\\n')\n",
    "print(f\"{index} Industry {industry} - {generated_question_count} questions - {proportional_question_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_questions = GetQuestionRequest(knowledge_base_id=350, label_method_type='generated')\n",
    "questions = get_questions(h, r_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_questions = GetQuestionRequest(knowledge_base_id=350, label_method_type='generated')\n",
    "response_questions = get_questions(h, r_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sections = GetSectionRequest(knowledge_base_id=350, id=89805528)\n",
    "section_count = get_sections(h, r_sections)\n",
    "section_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions_ds = Dataset.from_json('generated_questions_2.jsonl')\n",
    "sections_ds = Dataset.from_json('corresponding_sections_2.jsonl')\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both datasets:\n",
    "questions_ds.save_to_disk('generated_questions')\n",
    "sections_ds.save_to_disk('corresponding_sections')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-chat-gippity-4KQA4ztE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
